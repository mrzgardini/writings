Viaggio del fine settimana tra i miei segnalibri del browser col machine learning di python

> Copyright Control, ZHU, S. Zhu, J. Young - Hometown girl <a href='https://youtube.com/watch?v=7qQ02jx6pks'>https://youtube.com/watch?v=7qQ02jx6pks</a>

Sono veramente tanti.

<center><img src'documenti/170320241657.jpg'></img></center>

Per prima cosa gli ho esportati in un file html e poi convertiti in un database sql.

<pre>
%pip install bookmarks-converter

from bookmarks_converter import BookmarksConverter

segnalibri = BookmarksConverter("segnalibri.html")

segnalibri.parse("html")

segnalibri.convert("db")

segnalibri.save()
<pre>

Ora posso farci un'interrogazione sql che mi riporti tutte le righe del database in un file csv.

<pre>
con = sqlite3.connect('output_segnalibri_001.db')

cur = con.cursor()

df = pd.read_sql_query('SELECT * FROM bookmark', con)

df.to_csv('segnalibri-train.csv')
</pre>

In questi due giorni ho messo a punto questo codice che impara a classificare i segnalibri in base all'url.

Qui importo i segnalibri nel programma e levo le colonne della tabella che non mi servono.

<pre>
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB, ComplementNB
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, classification_report

df = pd.read_csv("segnalibri-train.csv")

df = df.drop(['Unnamed: 0'], axis=1)
df = df.drop(['id'], axis=1)
df = df.drop(['index'], axis=1)
df = df.drop(['date_added'], axis=1)
df = df.drop(['type'], axis=1)
df = df.drop(['icon'], axis=1)
df = df.drop(['icon_uri'], axis=1)
df = df.drop(['tags'], axis=1)
</pre>

Le categorie sono codificate con dei codici, le rinomino.

<pre>
df.parent_id = df.parent_id.replace(1.0, 'none')
df.parent_id = df.parent_id.replace(3.0, 'none')
df.parent_id = df.parent_id.replace(4.0, 'cultura')
df.parent_id = df.parent_id.replace(1839.0, 'difesa')
df.parent_id = df.parent_id.replace(2012.0, 'economia')
df.parent_id = df.parent_id.replace(2292.0, 'enciclopedia')
df.parent_id = df.parent_id.replace(5672.0, 'informatica')
df.parent_id = df.parent_id.replace(8577.0, 'libri')
df.parent_id = df.parent_id.replace(9334.0, 'matematica')
df.parent_id = df.parent_id.replace(13608.0, 'media')
df.parent_id = df.parent_id.replace(14935.0, 'varie')
df.parent_id = df.parent_id.replace(15161.0, 'social')
df.parent_id = df.parent_id.replace(17904.0, 'animali')
</pre>

Preparo i dati. In sostanza sklearn digerisce solo numeri, quindi converto tutti i testi in numeri.

<pre>
X = df['url'].astype(str)
y = df['parent_id'].astype(str)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

pipeMNB = Pipeline([
('tfidf', TfidfVectorizer()),('clf', MultinomialNB())
])
</pre>

Alleno il modello.

<pre>
pipeMNB.fit(X_train, y_train)
</pre>

E faccio una previsione con un nuovo segnalibro che non ho ancora catalogato.

<pre>
url = "www.google.com"
result = pipeMNB.predict([url])
print("Categoria: ", result[0])
</pre>

<pre>
Categoria:  enciclopedia
</pre>

Yeee! Sbaglia come pochi ma funzionaaa.
